{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Text_classification using huggingface transformers**"
      ],
      "metadata": {
        "id": "esr1Ammt9_ng"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeNCz6O18ZJ4",
        "outputId": "2c05c643-f22a-4a33-a47b-8cede66e26ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.931908905506134}]\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "llm=pipeline(\"text-classification\")\n",
        "text=\"well done budy!\"\n",
        "print(llm(text[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text translation from one language to another.**"
      ],
      "metadata": {
        "id": "qOMWKuoK-5qj"
      }
    },
    {
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "llm = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-mr\")\n",
        "text = \"how are you today?\"\n",
        "output = llm(text)\n",
        "print(output[0][\"translation_text\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rblWwVRE-dxV",
        "outputId": "e90db9ba-a77c-47e3-b29a-4e5ed214c725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "आज तू काय करतोयस?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text generation**"
      ],
      "metadata": {
        "id": "m3cKIL69_Kob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm=pipeline(\"text-generation\")\n",
        "text=\"to become a python developer you need to\"\n",
        "result=llm(text,max_length=50,do_sample=True)\n",
        "print(result[0][\"generated_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEVJS1Z88ku6",
        "outputId": "b6e45000-876d-4f6d-cade-bc268490edd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to become a python developer you need to install Python and PyPy the same way. The code will work as expected on any computer with Windows, Mac or Linux. However if you are using Java and Python for your projects a simple way might be to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=pipeline(\"text-generation\",model=\"gpt2\")\n",
        "text=\"to become a python developer you need to\"\n",
        "result=llm(text,max_length=50,do_sample=True)\n",
        "print(result[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nul1CjGM9HmO",
        "outputId": "f163e7db-f07f-48a7-a179-41b3215ba268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "to become a python developer you need to build your projects by the time you finish and finish your training. In this tutorial I'm going to do 5 different approaches to starting a python application from scratch using Django.\n",
            "\n",
            "After your code is written,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text summarization **"
      ],
      "metadata": {
        "id": "p8L8C_9sCzL7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm=pipeline(\"summarization\")\n",
        "long_text=\"Show drafts\\\n",
        "volume_up Artificial intelligence (AI) is a rapidly evolving field of computer science that aims to create intelligent machines capable of mimicking human cognitive functions. AI encompasses a wide range of techniques, including machine learning, deep learning, natural language processing, and computer vision. By analyzing vast amounts of data, AI systems can learn to perform tasks, make predictions, and even generate creative content. AI has the potential to revolutionize many aspects of our lives, from healthcare and transportation to business and entertainment. However, ethical considerations surrounding AI bias, transparency, and potential job displacement are crucial issues to address.pen_spark tune share more_vert\"\n",
        "print(\"Before summarization:\",len(long_text))\n",
        "result=llm(long_text)\n",
        "print(result[0][\"summary_text\"])\n",
        "print(\"After summarization\",len(result[0][\"summary_text\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCDFIMoJ_X5M",
        "outputId": "ebd88c50-1538-475e-b07b-a5148ef5d07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Your max_length is set to 142, but your input_length is only 132. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=66)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before summarization: 740\n",
            " Artificial intelligence (AI) aims to create intelligent machines capable of mimicking human cognitive functions . AI encompasses a wide range of techniques, including machine learning, deep learning, natural language processing, and computer vision . By analyzing vast amounts of data, AI systems can learn to perform tasks, make predictions, and even generate creative content .\n",
            "After summarization 380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quastion Answering **"
      ],
      "metadata": {
        "id": "XFzPqq6MD0V6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm=pipeline(\"question-answering\")\n",
        "context=\"Show drafts volume_up Artificial intelligence (AI) is a rapidly evolving field of computer science that aims to create intelligent \\\n",
        "machines capable of mimicking human cognitive functions. AI encompasses a wide range of techniques, including machine learning, deep learning, \\\n",
        "natural language processing, and computer vision. By analyzing vast amounts of data, AI systems can learn to perform tasks, make predictions,\\\n",
        " and even generate creative content. AI has the potential to revolutionize many aspects of our lives, \\\n",
        " from healthcare and transportation to business and entertainment. However, ethical considerations surrounding AI bias, transparency,\\\n",
        "  and potential job displacement are crucial issues to address.pen_spark tune share more_vert \"\n",
        "question=\"what is artificial intelligence?\"\n",
        "result=llm(question=question,context=context)\n",
        "print(result[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBwRc_6tBLXP",
        "outputId": "c195720e-4f52-4e6a-d0b9-f9890b5e0d02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a rapidly evolving field of computer science\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6GJBJpxDt6M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}